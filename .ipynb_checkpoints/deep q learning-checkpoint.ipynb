{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e414826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from environment import robot_env\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc64dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inisialisasi hyperparameter\n",
    "num_episodes = 10\n",
    "max_steps_per_episode = 100\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount_rate = 0.99\n",
    "\n",
    "epsilon = 1\n",
    "max_epsilon = 1\n",
    "min_epsilon = 0.1\n",
    "epsilon_decay_rate = 0.1\n",
    "batch_size = 32\n",
    "memory = deque(maxlen=2500)\n",
    "\n",
    "#Change to true if you want render training process\n",
    "render = False\n",
    "#Membuat Environment\n",
    "env = robot_env.initialize_env()\n",
    "\n",
    "#menginisialisasi posisi robot pertama kali (row_start, row_end, env)\n",
    "env = robot_env.initialize_position(0, 0, env)\n",
    "\n",
    "#Membuat array yang berisikan action apa saja yang bisa diambil\n",
    "actions = robot_env.action_space()\n",
    "# kiri = 0, kanan = 1, atas = 2, bawah = 3\n",
    "\n",
    "#inisialisasi reward\n",
    "#Reward :\n",
    "#Empty = -1\n",
    "#Fire = -10\n",
    "#2 Harta = +25\n",
    "#1 Harta = +10\n",
    "reward_all_episode = []\n",
    "\n",
    "epsilon_lst = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93839109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "    model=Sequential()\n",
    "    model.add(layers.Dense(10, input_shape=(12, ), activation='relu'))\n",
    "    model.add(layers.Dense(actions.size, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "def choose_action(epsilon, state):\n",
    "    random_num = random.uniform(0, 1)\n",
    "    \n",
    "    if (random_num < epsilon):\n",
    "        action = np.random.choice(actions, 1)[0]\n",
    "        \n",
    "    else:\n",
    "        state = env.flatten().reshape([1,12])\n",
    "        action = np.argmax(model.predict(state))\n",
    "        \n",
    "    return action\n",
    "        \n",
    "def pred():\n",
    "    state = env.flatten().reshape([1,12])\n",
    "    return np.argmax(model.predict(state))\n",
    "\n",
    "\n",
    "def add_memory(new_state, reward, done, state, action):\n",
    "    memory.append((new_state, reward, done, state, action))\n",
    "    \n",
    "    \n",
    "def replay(batch_size):\n",
    "    global epsilon\n",
    "    \n",
    "    minibatch=random.sample(memory, batch_size)\n",
    "    \n",
    "    for new_state, reward, done, state, action in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target=reward + discount_rate* np.amax(model.predict(new_state))\n",
    "        target_f= model.predict(state)\n",
    "        target_f[0][action]= target\n",
    "        model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "    if (epsilon > min_epsilon):\n",
    "        epsilon=(max_epsilon - min_epsilon) * np.exp(-epsilon_decay_rate*episode) + min_epsilon\n",
    "\n",
    "    epsilon_lst.append(epsilon)\n",
    "\n",
    "def load(name):\n",
    "    model.load_weights(name)\n",
    "\n",
    "def save(name):\n",
    "    model.save_weights(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce77caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f853755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* EPISODE  0  *******\n",
      "******* EPISODE  1  *******\n",
      "******* EPISODE  2  *******\n",
      "******* EPISODE  3  *******\n",
      "******* EPISODE  4  *******\n",
      "******* EPISODE  5  *******\n",
      "******* EPISODE  6  *******\n",
      "******* EPISODE  7  *******\n",
      "******* EPISODE  8  *******\n",
      "******* EPISODE  9  *******\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    env = robot_env.initialize_env()\n",
    "    env = robot_env.initialize_position(0, 0, env)\n",
    "    state = env.flatten().reshape([1,12])\n",
    "    done = False\n",
    "    rewards_current_episode = 0\n",
    "    print('******* EPISODE ',episode, ' *******')\n",
    "    for step in range(max_steps_per_episode):\n",
    "        #choose action  (epislon greedy)\n",
    "        action = choose_action(epsilon, state)\n",
    "        #take action and get reward and next state\n",
    "        new_state, reward, done, env = robot_env.take_action(action, env, render)\n",
    "        new_state = env.flatten().reshape([1,12])\n",
    "        add_memory(new_state, reward, done, state, action)\n",
    "        if render :\n",
    "            clear_output(wait=True)\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        \n",
    "        #change current state\n",
    "        state = new_state.copy()\n",
    "        rewards_current_episode += reward \n",
    "        \n",
    "        #check if already on termination state\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    #Add current episode reward to all episode reward\n",
    "    reward_all_episode.append(rewards_current_episode)\n",
    "    if len(memory)> batch_size:\n",
    "        replay(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52f30c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 23, 24, -19, 14, 21, -15, 22, -25, 24]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_all_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5342b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
